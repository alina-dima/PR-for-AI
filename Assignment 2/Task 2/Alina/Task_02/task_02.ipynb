{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: Add imblearn to requirements\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(data_path):\n",
    "    \"\"\"\n",
    "    Reads and processes data from specified path in data_path. \n",
    "    Data is balanced with SMOTE, and split into test, labelled train, and unlabelled train sets.\n",
    "\n",
    "    Return: unlabelled and labelled sets, test set, where x_jjjj are data and y_jjjj are labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df.drop(columns=[\"Amount\", \"Time\"])\n",
    "    labels = df[\"Class\"]\n",
    "    data = df.drop(columns=[\"Class\"])\n",
    "\n",
    "    ratio = min(labels.value_counts())/(max(labels.value_counts())/2)\n",
    "    # Undersamples half of majority class \n",
    "    rnd_under_sam = RandomUnderSampler(sampling_strategy=ratio, random_state=42)\n",
    "    data_res, labels_res = rnd_under_sam.fit_resample(data, labels)\n",
    "    # Oversamples data\n",
    "    sm = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "    data_res, labels_res = sm.fit_resample(data_res, labels_res)\n",
    "    return data_res, labels_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels):\n",
    "    \"\"\"\n",
    "    Splits data into test, and labelled and unlaballed train sets.\n",
    "    \"\"\"\n",
    "    # Split into train and test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2,\n",
    "                                                        stratify=labels)\n",
    "    # Split train into unlabelled and labelled train sets\n",
    "    x_train_unlab, x_train_lab, y_train_unlab, y_train_lab = \\\n",
    "        train_test_split(x_train, y_train, test_size=0.3, stratify=y_train)\n",
    "    y_train_unlab = pd.Series(-1, index=y_train_unlab.index, name='Class')\n",
    "\n",
    "    return x_train_unlab, y_train_unlab, x_train_lab, y_train_lab, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "  def __init__(self, model, name):\n",
    "    self.model = model\n",
    "    self.name = name\n",
    "\n",
    "def run_model(model, train_data, train_labels, test_data, test_labels):\n",
    "    \"\"\"\n",
    "    Runs a model and returns accuracy and f1\n",
    "    \"\"\"\n",
    "    model.fit(train_data, train_labels)\n",
    "    yhat = model.predict(test_data)\n",
    "    yhat = [int(i) for i in yhat]\n",
    "    accuracy = accuracy_score(test_labels, yhat)\n",
    "    f_1 = f1_score(test_labels, yhat)\n",
    "    return [accuracy, f_1], model\n",
    "\n",
    "def plot_results(accuracy, f1, title):\n",
    "    x = [i for i in range(len(f1))]\n",
    "    plt.plot(x, accuracy, label='Accuracy')\n",
    "    plt.plot(x, f1, label='F1 score')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.savefig(title + '.eps', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './creditcard.csv'\n",
    "# Reading and balancing data\n",
    "data, labels = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects the baseline classification and SSL models\n",
    "baseline = Model(RandomForestClassifier(), \"Random Forest\")\n",
    "ssl = Model(LabelPropagation(kernel='knn', n_jobs=6), \"KNN Label Propagation\")\n",
    "accuracy_baseline = []\n",
    "f1_baseline = []\n",
    "accuracy_ssl = []\n",
    "f1_ssl = []\n",
    "accuracy_baseline_ssl = []\n",
    "f1_baseline_ssl = []\n",
    "n_iter = 100\n",
    "\n",
    "for iter in range(n_iter):\n",
    "    x_train_unlab, y_train_unlab, x_train_lab, y_train_lab, x_test, y_test = split_data(data, labels)\n",
    "\n",
    "    # Runs classification model on lab train data and tests it\n",
    "    print(iter, \"Running baseline model on labeled data...\")\n",
    "    results, _ = run_model(baseline.model, x_train_lab, y_train_lab, x_test, y_test)\n",
    "    accuracy_baseline.append(results[0])\n",
    "    f1_baseline.append(results[1])\n",
    "\n",
    "    # Runs SSL model on all training data and tests it\n",
    "    x_train = pd.concat([x_train_lab, x_train_unlab], axis=0)\n",
    "    y_ssl = pd.concat([y_train_lab, y_train_unlab], axis=0)\n",
    "    #print(\"Running SSL model...\")\n",
    "    results, ssl_model = run_model(ssl.model, x_train, y_ssl, x_test, y_test)\n",
    "    accuracy_ssl.append(results[0])\n",
    "    f1_ssl.append(results[1])\n",
    "\n",
    "    # Runs baseline model on all training data using the labels obtained from SSL and tests it\n",
    "    y_train_ssl = ssl_model.transduction_\n",
    "    #print(\"Running baseline model with SSL labels on all data...\")\n",
    "    results, _ = run_model(baseline.model, x_train, y_train_ssl, x_test, y_test)\n",
    "    accuracy_baseline_ssl.append(results[0])\n",
    "    f1_baseline_ssl.append(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(accuracy_baseline, f1_baseline, 'Baseline')\n",
    "plot_results(accuracy_ssl, f1_ssl , 'Semi-supervised')\n",
    "plot_results(accuracy_baseline_ssl, f1_baseline_ssl, 'Baseline+semi-supervised')\n",
    "print(\"Baseline:\\nMean accuracy: {} \\nMean f1: {}\".format(np.mean(accuracy_baseline), np.mean(f1_baseline)))\n",
    "print(\"Baseline:\\nMean accuracy: {} \\nMean f1: {}\".format(np.mean(accuracy_ssl), np.mean(f1_ssl)))\n",
    "print(\"Baseline:\\nMean accuracy: {} \\nMean f1: {}\".format(np.mean(accuracy_baseline_ssl), np.mean(f1_baseline_ssl)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
